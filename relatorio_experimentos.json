{
  "experimentos": [
    {
      "grupo": "IA Generativa (Agentes)",
      "nome": "Classificador de Textos usando Cluster of Agents - CoA",
      "paradigma": "IA Generativa",
      "modelo": ["GPT4o", "Llama3", "KeyBERT", "SBERT"],
      "pipeline": [
        "OCR for text extraction",
        "Dataset split (train-test)",
        "CoA build-up",
        "CoA prompt training",
        "CoA experience library",
        "CoA prompt test"
      ],
      "hiperparametros": {},
      "resultados": {
        "sensibilidade": 0.0,
        "especificidade": 0.0,
        "precisao": 0.0,
        "acuracia": 0.0,
        "f1score": 0.0
      },
      "observacoes": "Proposta inovadora, porém o seu tempo de desenvolvimento foi mal dimensionado por não considerar o gerenciamento de fluxo de tokens na API do modelo gpt_4o, o gerenciamento de memória RAM e o gerenciamento do aprendizado do modelo gpt_4o. Por fins administrativos, esse caso foi congelado, podendo ser reativado posteriormente.",
      "orientacoes": {
        "sensibilidade": "Necessário executar o pipeline integralmente.",
        "especificidade": "Necessário executar o pipeline integralmente.",
        "precisao": "Necessário executar o pipeline integralmente.",
        "acuracia": "Necessário executar o pipeline integralmente.",
        "f1score": "Necessário executar o pipeline integralmente."
      },
      "impacto": "Necessário executar o pipeline integralmente."
    },
    {
      "grupo": "IA Generativa (LLMs)",
      "nome": "Classificador de textos sumarizados LLM",
      "paradigma": "IA Generativa",
      "modelo": ["Llama3", "XL-Sum"],
      "pipeline": [
        "OCR for text extraction",
        "Text Summarization",
        "Dataset split (train, test)",
        "Dataset Tokenization",
        "Model LoRA training",
        "Model test"
      ],
      "hiperparametros": {},
      "resultados": {
        "sensibilidade": 0.70,
        "especificidade": 0.33,
        "precisao": 0.50,
        "acuracia": 0.51,
        "f1score": 0.58
      },
      "observacoes": "Performance limitada por sumarização excessiva, resultando em perda de contexto jurídico relevante.",
      "orientacoes": {
        "sensibilidade": "Reconhece parte significativa dos bloqueios.",
        "especificidade": "Pouca habilidade em diferenciar não-bloqueios.",
        "precisao": "Razoável para tarefas de triagem inicial.",
        "acuracia": "Necessita melhoria para uso produtivo.",
        "f1score": "Necessário revisar abordagem de sumarização."
      },
      "impacto": "Serve como baseline para experimentos futuros envolvendo sumarização e LLMs."
    },
    {
      "grupo": "IA Generativa (LLMs)",
      "nome": "Classificador de textos inteiros LLM",
      "paradigma": "IA Generativa",
      "modelo": ["Llama3", "SBERT"],
      "pipeline": [
        "OCR for text extraction",
        "Dataset split (train, test)",
        "Dataset Tokenization",
        "Model LoRA training",
        "Model test"
      ],
      "hiperparametros": {},
      "resultados": {
        "sensibilidade": 0.40,
        "especificidade": 0.28,
        "precisao": 0.34,
        "acuracia": 0.34,
        "f1score": 0.36
      },
      "observacoes": "Perda acentuada de performance sem sumarização. Indica limitação do modelo ao tratar textos extensos.",
      "orientacoes": {
        "sensibilidade": "Risco elevado de deixar de detectar bloqueios.",
        "especificidade": "Baixa confiança para não-bloqueios.",
        "precisao": "Não recomendado para produção.",
        "acuracia": "Modelo subótimo frente ao contexto.",
        "f1score": "Requer reformulação da estratégia de entrada."
      },
      "impacto": "Evidencia a necessidade de ajuste fino para uso de LLMs em textos longos."
    },
    {
      "grupo": "Machine Learning Clássico",
      "nome": "Random Forest com TF-IDF",
      "paradigma": "Machine Learning",
      "modelo": ["TF-IDF", "RandomForest"],
      "pipeline": [
        "OCR for text extraction",
        "Text cleaning & normalization",
        "TF-IDF vectorization",
        "Dataset split (train, test)",
        "RandomForest training (grid search)",
        "Model test"
      ],
      "hiperparametros": {
        "n_estimators": [100, 200, 300],
        "max_depth": [3, 5, 7],
        "tfidf__max_features": [1000, 2000],
        "tfidf__ngram_range": [[1, 1], [1, 2]]
      },
      "resultados": {
        "sensibilidade": 0.74,
        "especificidade": 0.70,
        "precisao": 0.73,
        "acuracia": 0.73,
        "f1score": 0.73
      },
      "observacoes": "Modelo robusto, resultados consistentes, mas aquém do XGBoost.",
      "orientacoes": {
        "sensibilidade": "Reconhece a maioria dos bloqueios, margem para ajuste.",
        "especificidade": "Razoável separação dos não-bloqueios.",
        "precisao": "Adequado para ambientes menos exigentes.",
        "acuracia": "Útil para base comparativa.",
        "f1score": "Soluções superiores disponíveis."
      },
      "impacto": "Base sólida para testes comparativos de modelos clássicos."
    },
    {
      "grupo": "Machine Learning Clássico",
      "nome": "Logistic Regression com TF-IDF",
      "paradigma": "Machine Learning",
      "modelo": ["TF-IDF", "LogisticRegression"],
      "pipeline": [
        "OCR for text extraction",
        "Text cleaning & normalization",
        "TF-IDF vectorization",
        "Dataset split (train, test)",
        "LogisticRegression training (grid search)",
        "Model test"
      ],
      "hiperparametros": {
        "C": [0.1, 1.0, 10.0],
        "tfidf__max_features": [1000, 2000],
        "tfidf__ngram_range": [[1, 1], [1, 2]]
      },
      "resultados": {
        "sensibilidade": 0.75,
        "especificidade": 0.71,
        "precisao": 0.73,
        "acuracia": 0.73,
        "f1score": 0.73
      },
      "observacoes": "Resultados estáveis, pouca vantagem frente a Random Forest.",
      "orientacoes": {
        "sensibilidade": "Boa identificação de bloqueios.",
        "especificidade": "Pode ser melhorada com novos dados.",
        "precisao": "Útil para cenários de decisão rápida.",
        "acuracia": "Recomendado para validação cruzada.",
        "f1score": "Modelo simples, manutenção facilitada."
      },
      "impacto": "Opção de baixa complexidade para validação."
    },
    {
      "grupo": "Machine Learning Clássico",
      "nome": "SVM com TF-IDF",
      "paradigma": "Machine Learning",
      "modelo": ["TF-IDF", "SVM"],
      "pipeline": [
        "OCR for text extraction",
        "Text cleaning & normalization",
        "TF-IDF vectorization",
        "Dataset split (train, test)",
        "SVM training (grid search)",
        "Model test"
      ],
      "hiperparametros": {
        "C": [0.1, 1.0, 10.0],
        "kernel": ["linear", "rbf"],
        "tfidf__max_features": [1000, 2000],
        "tfidf__ngram_range": [[1, 1], [1, 2]]
      },
      "resultados": {
        "sensibilidade": 0.74,
        "especificidade": 0.71,
        "precisao": 0.73,
        "acuracia": 0.73,
        "f1score": 0.73
      },
      "observacoes": "Performance similar aos demais modelos clássicos.",
      "orientacoes": {
        "sensibilidade": "Satisfatório na detecção de bloqueios.",
        "especificidade": "Aprimorável com tuning avançado.",
        "precisao": "Boa precisão geral.",
        "acuracia": "Adequado para ambientes controlados.",
        "f1score": "Não supera XGBoost."
      },
      "impacto": "Complementar para estratégias ensemble."
    },
    {
      "grupo": "Machine Learning Clássico",
      "nome": "MLP (Multilayer Perceptron) com TF-IDF",
      "paradigma": "Machine Learning",
      "modelo": ["TF-IDF", "MLP"],
      "pipeline": [
        "OCR for text extraction",
        "Text cleaning & normalization",
        "TF-IDF vectorization",
        "Dataset split (train, test)",
        "MLP training (grid search)",
        "Model test"
      ],
      "hiperparametros": {
        "hidden_layer_sizes": [[50], [100]],
        "activation": ["relu", "tanh"],
        "max_iter": [200, 500],
        "tfidf__max_features": [1000, 2000],
        "tfidf__ngram_range": [[1, 1], [1, 2]]
      },
      "resultados": {
        "sensibilidade": 0.76,
        "especificidade": 0.74,
        "precisao": 0.75,
        "acuracia": 0.75,
        "f1score": 0.75
      },
      "observacoes": "MLP apresentou ligeira vantagem. Requer ajuste fino em dados maiores.",
      "orientacoes": {
        "sensibilidade": "Ligeira vantagem sobre outros clássicos.",
        "especificidade": "Boa separação das classes.",
        "precisao": "Recomendado para cenários dinâmicos.",
        "acuracia": "Versátil em diferentes bases.",
        "f1score": "Ótimo custo-benefício."
      },
      "impacto": "Versatilidade destacada para múltiplos cenários."
    },
    {
      "grupo": "Machine Learning Clássico",
      "nome": "XGBoost com TF-IDF (Melhor resultado)",
      "paradigma": "Machine Learning",
      "modelo": ["TF-IDF", "XGBoost"],
      "pipeline": [
        "OCR for text extraction",
        "Text cleaning & normalization",
        "TF-IDF vectorization",
        "Dataset split (train, test)",
        "XGBoost training (grid search)",
        "Model test"
      ],
      "hiperparametros": {
        "learning_rate": 0.1,
        "max_depth": 3,
        "n_estimators": 50,
        "tfidf__max_features": 1000,
        "tfidf__ngram_range": [1, 2]
      },
      "resultados": {
        "sensibilidade": 0.90,
        "especificidade": 0.81,
        "precisao": 0.82,
        "acuracia": 0.85,
        "f1score": 0.86
      },
      "observacoes": "Modelo de melhor performance no ciclo atual. Métricas superam o baseline acordado. A configuração indicada atingiu ótimo equilíbrio entre sensibilidade, especificidade e precisão.",
      "orientacoes": {
        "sensibilidade": "Modelo está altamente apto a identificar bloqueios corretamente.",
        "especificidade": "Boa discriminação de não-bloqueios, baixo risco de falsos positivos.",
        "precisao": "Excelente separação de classes, apto para cenários reais.",
        "acuracia": "Pronto para uso produtivo, desde que monitorado e atualizado periodicamente.",
        "f1score": "Modelo muito equilibrado para o contexto jurídico dos ofícios."
      },
      "impacto": "Referência para produção. Recomendado como ponto de partida para novas versões e escalabilidade."
    },
    {
      "grupo": "Teste Real com Massa Nova",
      "nome": "Validação do melhor modelo com dados inéditos (XGBoost + TF-IDF)",
      "paradigma": "Machine Learning",
      "modelo": ["TF-IDF", "XGBoost"],
      "pipeline": [
        "OCR for text extraction",
        "Text cleaning & normalization",
        "TF-IDF vectorization",
        "Aplicação do modelo treinado",
        "Avaliação sobre 100 ofícios não vistos"
      ],
      "hiperparametros": {
        "learning_rate": 0.1,
        "max_depth": 3,
        "n_estimators": 50,
        "tfidf__max_features": 1000,
        "tfidf__ngram_range": [1, 2]
      },
      "resultados": {
        "sensibilidade": 0.48,
        "especificidade": 0.90,
        "precisao": 0.79,
        "acuracia": 0.64,
        "f1score": 0.59
      },
      "observacoes": "O desempenho caiu ao testar com nova massa de dados, principalmente na sensibilidade. O modelo manteve ótima especificidade e precisão, mas demonstrou dificuldade para detectar novos casos de bloqueio.",
      "orientacoes": {
        "sensibilidade": "Priorizar análise de erros de falsos negativos; revisar diversidade dos exemplos de bloqueio no treinamento.",
        "especificidade": "Modelo robusto para não-bloqueios; cuidado com overfitting para exemplos negativos.",
        "precisao": "Bom para aplicações que valorizam minimizar falsos positivos.",
        "acuracia": "Requer incremento de dados e possíveis novas features.",
        "f1score": "Sugere necessidade de ajustes finos no pipeline e avaliação de alternativas de extração de texto."
      },
      "impacto": "A queda de sensibilidade evidencia limitação de generalização do modelo; nova etapa de investigação é crucial para evolução da solução."
    }
  ]
}