{
  "experimentos": [
    {
      "grupo": "IA Generativa (Agentes)",
      "nome": "Cluster of Agents (GPT-4o + Llama3)",
      "paradigma": "IA Generativa",
      "modelo": "Cluster of Agents com GPT-4o e Llama3",
      "pipeline": [
        "Divisão dos ofícios por rótulo alvo",
        "Execução de prompts e sumarização via API GPT-4o/Llama3",
        "Agregação de outputs",
        "Decisão via heurística"
      ],
      "hiperparametros": {},
      "resultados": {
        "sensibilidade": 0.0,
        "especificidade": 0.0,
        "precisao": 0.0,
        "acuracia": 0.0,
        "f1score": 0.0
      },
      "observacoes": "Proposta inovadora, mas dependente de recursos computacionais externos e de curadoria humana. Impraticável sem infra dedicada.",
      "orientacoes": {
        "sensibilidade": ["Não mensurada por falta de dados."],
        "especificidade": ["Não mensurada por falta de dados."],
        "precisao": ["Não mensurada por falta de dados."],
        "acuracia": ["Pipeline interrompido por limitações práticas."],
        "f1score": ["Recomenda-se reavaliar abordagem para contextos futuros."]
      },
      "impacto": "Apesar do alto potencial, a abordagem esbarrou em limitações práticas de custo e escalabilidade."
    },
    {
      "grupo": "Machine Learning Clássico",
      "nome": "Random Forest",
      "paradigma": "Machine Learning Clássico",
      "modelo": "RandomForestClassifier",
      "pipeline": [
        "OCR Tesseract",
        "TF-IDF Vectorizer",
        "Random Forest Classifier"
      ],
      "hiperparametros": {
        "n_estimators": [100, 200],
        "max_depth": [5, 10, 15],
        "max_features": ["auto", "sqrt"]
      },
      "resultados": {
        "sensibilidade": 0.71,
        "especificidade": 0.65,
        "precisao": 0.68,
        "acuracia": 0.76,
        "f1score": 0.69
      },
      "observacoes": "Desempenho razoável, mas instável em classes desbalanceadas.",
      "orientacoes": {
        "sensibilidade": [
          "Aumentar amostras positivas pode melhorar o recall.",
          "Analisar se há viés de amostragem.",
          "Reforçar balanceamento de classes.",
          "Investigar possíveis overfits."
        ],
        "especificidade": [
          "Especificidade pode ser ampliada com features exclusivas para não-bloqueio.",
          "Testar regularização.",
          "Comparar com outros modelos para ajuste fino.",
          "Cuidado com ofícios atípicos."
        ],
        "precisao": [
          "Otimize limiar de decisão.",
          "Testar combinações de features textuais.",
          "Priorizar ofícios com risco jurídico.",
          "Usar amostras hard-negative."
        ],
        "acuracia": [
          "Expandir base de dados.",
          "Ajustar hiperparâmetros via grid search.",
          "Avaliar outras técnicas de ensemble.",
          "Monitorar possíveis desvios temporais."
        ],
        "f1score": [
          "Equilíbrio geral bom, mas foco na diversidade de dados pode ajudar.",
          "Aprimorar análise dos casos limítrofes.",
          "Monitorar efeitos de truncagem do texto.",
          "Testar hibridação com embeddings."
        ]
      },
      "impacto": "Solução prática, fácil de implementar e entender. Útil para cenários com recursos limitados, mas requer monitoramento contínuo."
    },
    {
      "grupo": "Machine Learning Clássico",
      "nome": "Logistic Regression",
      "paradigma": "Machine Learning Clássico",
      "modelo": "LogisticRegression",
      "pipeline": [
        "OCR Tesseract",
        "TF-IDF Vectorizer",
        "Logistic Regression Classifier"
      ],
      "hiperparametros": {
        "C": [0.1, 1.0, 10],
        "penalty": ["l2"],
        "solver": ["liblinear"]
      },
      "resultados": {
        "sensibilidade": 0.75,
        "especificidade": 0.71,
        "precisao": 0.73,
        "acuracia": 0.75,
        "f1score": 0.74
      },
      "observacoes": "Modelo simples, mas robusto para baseline. Pode ser sensível a features não-informativas.",
      "orientacoes": {
        "sensibilidade": [
          "Cuidado com texto OCR truncado.",
          "Validar se rótulos não estão ruidosos.",
          "Avaliar ajuste de limiar.",
          "Considerar regularização L1."
        ],
        "especificidade": [
          "Adicionar features para distinguir não-bloqueios.",
          "Aumentar amostras negativas.",
          "Monitorar confusões com documentos similares.",
          "Explorar bag-of-words mais amplo."
        ],
        "precisao": [
          "Balancear recall e precisão de acordo com a demanda jurídica.",
          "Testar penalidades customizadas.",
          "Verificar se há redundância de features.",
          "Ajustar peso das classes."
        ],
        "acuracia": [
          "Grid search contínuo pode otimizar resultado.",
          "Expandir e atualizar dataset periodicamente.",
          "Monitorar qualidade do OCR.",
          "Verificar proporção de treino/teste."
        ],
        "f1score": [
          "Verificar estabilidade ao longo dos meses.",
          "Aprimorar pré-processamento de texto.",
          "Incluir análise semântica de contexto.",
          "Checar outliers."
        ]
      },
      "impacto": "Ótima opção para projetos ágeis, onde transparência e velocidade são essenciais. Menos eficaz em contextos altamente variáveis."
    },
    {
      "grupo": "Machine Learning Clássico",
      "nome": "SVM",
      "paradigma": "Machine Learning Clássico",
      "modelo": "Support Vector Machine",
      "pipeline": [
        "OCR Tesseract",
        "TF-IDF Vectorizer",
        "SVM Classifier"
      ],
      "hiperparametros": {
        "C": [0.1, 1.0, 10],
        "kernel": ["linear", "rbf"]
      },
      "resultados": {
        "sensibilidade": 0.76,
        "especificidade": 0.74,
        "precisao": 0.75,
        "acuracia": 0.76,
        "f1score": 0.75
      },
      "observacoes": "Bom equilíbrio geral, porém pode ser computacionalmente caro em grandes massas.",
      "orientacoes": {
        "sensibilidade": [
          "Atenção ao ajuste do parâmetro C.",
          "Cuidado com overfitting em poucos exemplos.",
          "Expandir base de treinamento.",
          "Incluir features de posição/texto."
        ],
        "especificidade": [
          "Testar kernels distintos.",
          "Aumentar granularidade dos rótulos.",
          "Adicionar features sintéticas.",
          "Monitorar estabilidade temporal."
        ],
        "precisao": [
          "Avaliar impacto do OCR em diferentes tipos de documento.",
          "Testar thresholds alternativos.",
          "Balancear penalização de classes.",
          "Expandir análise semântica."
        ],
        "acuracia": [
          "Grid search em mais hiperparâmetros.",
          "Padronizar pré-processamento.",
          "Testar diferentes estratégias de split.",
          "Comparar com outros modelos clássicos."
        ],
        "f1score": [
          "Aprimorar features contextuais.",
          "Monitorar taxa de falsos positivos.",
          "Avaliar impacto de features raras.",
          "Revisar balanceamento do dataset."
        ]
      },
      "impacto": "Recomendado para datasets médios, com boa interpretabilidade e performance estável."
    },
    {
      "grupo": "Machine Learning Clássico",
      "nome": "MLP",
      "paradigma": "Machine Learning Clássico",
      "modelo": "Multilayer Perceptron",
      "pipeline": [
        "OCR Tesseract",
        "TF-IDF Vectorizer",
        "MLP Classifier"
      ],
      "hiperparametros": {
        "hidden_layer_sizes": ["100", "50/50"],
        "activation": ["relu", "tanh"],
        "alpha": [0.0001, 0.001]
      },
      "resultados": {
        "sensibilidade": 0.73,
        "especificidade": 0.74,
        "precisao": 0.73,
        "acuracia": 0.73,
        "f1score": 0.73
      },
      "observacoes": "Boa robustez, mas pode necessitar ajuste mais fino dos hiperparâmetros.",
      "orientacoes": {
        "sensibilidade": [
          "Expandir camadas pode ajudar recall.",
          "Regularização pode evitar overfit.",
          "Testar arquiteturas menores.",
          "Monitorar impacto de dropout."
        ],
        "especificidade": [
          "Incluir features adicionais (palavras-chave).",
          "Ajustar thresholds de ativação.",
          "Balancear dataset.",
          "Analisar padrão de erro."
        ],
        "precisao": [
          "Ajustar learning rate.",
          "Monitorar efeito de batch size.",
          "Aprimorar limpeza de texto.",
          "Revisar performance em subclasses."
        ],
        "acuracia": [
          "Re-treinar periodicamente.",
          "Padronizar pipeline de entrada.",
          "Checar consistência de rótulos.",
          "Documentar variações entre execuções."
        ],
        "f1score": [
          "Analisar exemplos mal classificados.",
          "Explorar técnicas de ensemble.",
          "Monitorar dispersão do score.",
          "Investigar padrões de sazonalidade."
        ]
      },
      "impacto": "Boa performance geral, especialmente em contextos com padrões claros e poucos outliers."
    },
    {
      "grupo": "Machine Learning Clássico",
      "nome": "XGBoost",
      "paradigma": "Machine Learning Clássico",
      "modelo": "XGBoostClassifier",
      "pipeline": [
        "OCR Tesseract",
        "TF-IDF Vectorizer",
        "XGBoost Classifier"
      ],
      "hiperparametros": {
        "learning_rate": [0.1],
        "max_depth": [7],
        "n_estimators": [200],
        "max_features": [2000],
        "ngram_range": [[1, 2]]
      },
      "resultados": {
        "sensibilidade": 0.90,
        "especificidade": 0.81,
        "precisao": 0.89,
        "acuracia": 0.85,
        "f1score": 0.86
      },
      "observacoes": "Melhor desempenho geral, superando modelos anteriores em todos os critérios.",
      "orientacoes": {
        "sensibilidade": [
          "Aumentar ainda mais dados de bloqueio pode potencializar recall.",
          "Testar com embeddings mais robustos.",
          "Checar possíveis duplicidades no dataset.",
          "Avaliar reamostragem em subclasses raras."
        ],
        "especificidade": [
          "Testar thresholds personalizados para não-bloqueio.",
          "Aprimorar features específicas do contexto jurídico.",
          "Validar performance em novos tribunais.",
          "Comparar com modelos de deep learning."
        ],
        "precisao": [
          "Ajustar penalização de erros críticos.",
          "Testar agregação de modelos (ensemble).",
          "Monitorar performance após updates de OCR.",
          "Expandir base de features contextuais."
        ],
        "acuracia": [
          "Expandir treinamento com novos dados rotulados.",
          "Automatizar monitoramento de drift.",
          "Documentar pipeline para novos times.",
          "Avaliar robustez em batches temporais."
        ],
        "f1score": [
          "Monitorar taxa de falsos negativos.",
          "Aprimorar tratamento de outliers.",
          "Testar regularização alternativa.",
          "Realizar explicabilidade com SHAP/LIME."
        ]
      },
      "impacto": "Alto potencial de automação do fluxo de classificação de ofícios jurídicos, robusto frente a diferentes cenários e variações documentais."
    }
  ]
}
